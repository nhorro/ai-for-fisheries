{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7da85ea",
   "metadata": {},
   "source": [
    "# Pipeline para video analítico - Detección de objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a77312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from videoanalytics.pipeline import process_pipeline, Source, Sink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c40e7b",
   "metadata": {},
   "source": [
    "Inicialización de Tensorflow (requerida para detector y extractor de features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1e8c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment out below line to enable tensorflow logging outputs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    \n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0e8d20",
   "metadata": {},
   "source": [
    "## Definición y ejecución de pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebbb39e",
   "metadata": {},
   "source": [
    "Definición de grafos y ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "301b2868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from videoanalytics.pipeline.sources import VideoReader\n",
    "from videoanalytics.pipeline.sinks import VideoWriter\n",
    "from videoanalytics.pipeline.sinks.yolo4_detector import YOLOv4Detector\n",
    "from videoanalytics.pipeline.sinks.obj_detector import DetectionsAnnotator, DetectionsCSVWriter, ObjectDetectorCSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a59513a",
   "metadata": {},
   "source": [
    "### 1. Pipeline para generar detecciones y guardar en CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2f7c8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start frame: 0\n",
      "Total frames frame: 18205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de18167961ba46bfa1cd0ba685b4c741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18205 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing pipeline\n",
      "Sequence: ['input', 'detector', 'detector-annot', 'writer', 'detector2csv']\n",
      "Processing pipeline\n",
      "Shutting down pipeline\n",
      "Shutting down VideoWriter. Video saved to ../outputs/prueba.mp4\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "INPUT_VIDEO = \"../data/video/barco.mp4\"\n",
    "START_FRAME = 0\n",
    "MAX_FRAMES = None\n",
    "\n",
    "# Object Detector\n",
    "DETECTOR_WEIGHTS_FILENAME = \"../checkpoints/yolov4-416\"\n",
    "\n",
    "# Detections Annotator\n",
    "DETECTOR_CLASSES_FILENAME = \"../data/classes/coco.names\"\n",
    "\n",
    "# Output\n",
    "OUTPUT_VIDEO = \"../outputs/prueba.mp4\"\n",
    "\n",
    "# 1. Crear el contexto en el que los bloques comparten información\n",
    "context = {}\n",
    "\n",
    "# 2. Instanciar la pipeline (grafo dirigido)\n",
    "pipeline = nx.DiGraph()\n",
    "\n",
    "# 3. Agregar bloques\n",
    "pipeline.add_nodes_from([\n",
    "    ( \"input\", {\n",
    "      \"component\": VideoReader(context,\n",
    "                               video_path=INPUT_VIDEO,\n",
    "                               start_frame=START_FRAME,\n",
    "                               max_frames=MAX_FRAMES)\n",
    "    }),\n",
    "    \n",
    "    ( \"detector\", {\n",
    "        \"component\": YOLOv4Detector(context,weights_filename=DETECTOR_WEIGHTS_FILENAME)\n",
    "    }),\n",
    "    \n",
    "    ( \"detector2csv\", {\n",
    "        \"component\": DetectionsCSVWriter(context)\n",
    "    }),    \n",
    "    \n",
    "    ( \"detector-annot\", {\n",
    "        \"component\": DetectionsAnnotator(context,class_names_filename=DETECTOR_CLASSES_FILENAME)\n",
    "    }),    \n",
    "        \n",
    "    ( \"writer\", {\n",
    "        \"component\": VideoWriter(context,filename=OUTPUT_VIDEO)\n",
    "    })\n",
    "])\n",
    "\n",
    "# 4. Definir conexiones\n",
    "pipeline.add_edges_from([\n",
    "    (\"input\", \"detector\"), \n",
    "    (\"detector\", \"detector2csv\"),\n",
    "    (\"detector\", \"detector-annot\"), \n",
    "    (\"detector-annot\", \"writer\")\n",
    "])\n",
    "\n",
    "# 5. Eliminar bloques aislados\n",
    "pipeline.remove_nodes_from(list(nx.isolates(pipeline)))\n",
    "\n",
    "# 6. Procesar el pipeline\n",
    "process_pipeline(pipeline,context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f6ed3",
   "metadata": {},
   "source": [
    "### 2. Pipeline que usa detecciones precalculadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17a3ba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start frame: 0\n",
      "Total frames frame: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31737336b1954fef84469c367ccc85ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing pipeline\n",
      "Sequence: ['input', 'detector', 'detector-annot', 'writer']\n",
      "Processing pipeline\n",
      "Shutting down pipeline\n",
      "Shutting down VideoWriter. Video saved to ../outputs/prueba.mp4\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "INPUT_VIDEO = \"../data/video/barco.mp4\"\n",
    "START_FRAME = 0\n",
    "MAX_FRAMES = 100\n",
    "\n",
    "# Detector\n",
    "CSV_DETECTIONS_FILENAME = \"detections.csv\"\n",
    "\n",
    "# Detections Annotator\n",
    "DETECTOR_CLASSES_FILENAME = \"../data/classes/coco.names\"\n",
    "\n",
    "# Output\n",
    "OUTPUT_VIDEO = \"../outputs/prueba.mp4\"\n",
    "\n",
    "# 1. Crear el contexto en el que los bloques comparten información\n",
    "context = {}\n",
    "\n",
    "# 2. Instanciar la pipeline (grafo dirigido)\n",
    "pipeline = nx.DiGraph()\n",
    "\n",
    "# 3. Agregar bloques\n",
    "pipeline.add_nodes_from([\n",
    "    ( \"input\", {\n",
    "      \"component\": VideoReader(context,\n",
    "                                 video_path=INPUT_VIDEO,\n",
    "                                 start_frame=START_FRAME,\n",
    "                                 max_frames=MAX_FRAMES)\n",
    "    }),\n",
    "    \n",
    "    ( \"detector\", {\n",
    "      \"component\": ObjectDetectorCSV(context,CSV_DETECTIONS_FILENAME)\n",
    "    }),\n",
    "    \n",
    "    ( \"detector-annot\", {\n",
    "      \"component\": DetectionsAnnotator(context,class_names_filename=DETECTOR_CLASSES_FILENAME)\n",
    "    }),    \n",
    "    \n",
    "    ( \"writer\", {\n",
    "      \"component\": VideoWriter(context,filename=OUTPUT_VIDEO)\n",
    "    })\n",
    "])\n",
    "\n",
    "# 4. Definir conexiones\n",
    "pipeline.add_edges_from([\n",
    "    (\"input\", \"detector\"), \n",
    "    (\"detector\", \"detector-annot\"), \n",
    "    (\"detector-annot\", \"writer\")\n",
    "])\n",
    "\n",
    "# 5. Eliminar bloques aislados\n",
    "pipeline.remove_nodes_from(list(nx.isolates(pipeline)))\n",
    "\n",
    "# 6. Procesar\n",
    "process_pipeline(pipeline,context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20cbf26",
   "metadata": {},
   "source": [
    "Cierre de sesión de tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80e5790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
