{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apuntes detección de objetos y YOLOv4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve_5USBpMxuH"
      },
      "source": [
        "# Detección de objetos y familia de algoritmos YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H7gsZ77OFi2"
      },
      "source": [
        "## 1. Descripción del problema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIDdogCZM9j6"
      },
      "source": [
        "## 2. Métricas de evaluación\n",
        "\n",
        "*AP* y *mAP* (por sus siglas en inglés *Average Precision* y *mean Average Precision*) son dos de las métricas más populares para evaluar el desempeño de un detector de objetos, y han sido utilizadas en competiciones como COCO, PASCAL y VOC.\n",
        "De estas métricas es posible dereivar otras como *AP50*, *AP75* y *AP[.5:.5:.95]*, por citar algunas.\n",
        "\n",
        "### Definiciones\n",
        "\n",
        "- True Positive (TP): una detección válida.\n",
        "- False Positive (FP): una detección inválida.\n",
        "- False Negative (FN): blanco no detectado.\n",
        "- True Negative (TN): esta métrica no se utiliza en detección de objetos, porque hay infinitas instancias que podrían no ser detectadas como un objeto.\n",
        "\n",
        "Intersection over Union\n",
        "\n",
        "$$\n",
        "IoU = \\frac{area(gt \\cap pd}{area(gt \\cup pd)}\n",
        "$$\n",
        "\n",
        "Se definen:\n",
        "\n",
        "- TP como una detección para la cual $IoU > \\alpha$.\n",
        "- FP como una detección para la cual $IoU < \\alpha$.\n",
        "- FN es un blanco no detectado por el modelo.\n",
        "\n",
        "### Precision y recall\n",
        "\n",
        "Dado que TN no existe en detección de objetos, se deben evitar métricas que utilicen este componente de la matriz de confusión como TNR (*True Negative Rate*), NPC (*Negative Predictive Value*) y ROC (*Receiver Operating Characteristic*). En cambio, para la evaluación de modelos de detección de objetos basada en Precision(P) y Recall(R) se definen:\n",
        "\n",
        "$$\n",
        "P = \\frac{TP}{TP+FP}\n",
        "$$\n",
        "\n",
        "$$\n",
        "R = \\frac{TP}{TP+FN}\n",
        "$$\n",
        "\n",
        "*Precision* es la habilidad que tenga el clasificador de identificar blancos relevantes unicamente. Es la proporción de detecciones correctas del total de existentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuH2YKGAfWLa"
      },
      "source": [
        "## 3. Familia de algoritmos YOLO\n",
        "\n",
        "### 3.1 YOLO\n",
        "\n",
        "### 3.2 YOLOv2,YOLOv3, YOLOv4\n",
        "\n",
        "### 3.3 Implementación DarkNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t4VaGIPfa47"
      },
      "source": [
        "## 4. Modelos entrenados y reporte de desempeño\n",
        "\n",
        "- Se ensayan modelos con distintas configuraciones y HPS, así como distintas preparaciones de datos de entrada.\n",
        "- Todos los modelos se entrenan sobre un dataset que se particiona en TRAIN, VALIDATION y TEST con una proporción (70,20,10) (ajustar dependiendo de disponibilidad de datos).\n",
        "- La partición de TEST se deja intacta y no es utilizada hasta que el modelo ha finalizado su entrenamiento. La evaluación para obtener las métricas de desempeño se hace sobre esta partición.\n",
        "- La partición de TRAIN puede ampliarse mediante técnicas de aumentado. La partición VALIDATION se utiliza para monitorear la evolución durante el entrenamiento y para calibración de hiperparámetros.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJPOJ3m9n5xC",
        "outputId": "d70d8569-66fe-4e1c-968e-9be29cbc43d3"
      },
      "source": [
        "!pip install object_detection_metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting object_detection_metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/89/1a150e96f6bc51a0eaca9c65be5268e87c32a90dc4a39ee851f710ca51c8/object-detection-metrics-0.1.tar.gz\n",
            "Building wheels for collected packages: object-detection-metrics\n",
            "  Building wheel for object-detection-metrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection-metrics: filename=object_detection_metrics-0.1-cp37-none-any.whl size=7782 sha256=2734f7eff85f3d472a320843e8dc913a27aeb1869d5597ff865a38a8427a2be6\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/70/73/55050c37c6506b98807687506eda3a3bc7d11d9cd2256be4da\n",
            "Successfully built object-detection-metrics\n",
            "Installing collected packages: object-detection-metrics\n",
            "Successfully installed object-detection-metrics-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZX1PY0oop8d",
        "outputId": "706f6fa6-4b95-4606-d9bb-988c1b9a3531"
      },
      "source": [
        "from podm import visualize\n",
        "help(visualize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on module podm.visualize in podm:\n",
            "\n",
            "NAME\n",
            "    podm.visualize\n",
            "\n",
            "FUNCTIONS\n",
            "    plot_precision_recall_curve(result: podm.podm.MetricPerClass, dest, method: podm.podm.MethodAveragePrecision = <MethodAveragePrecision.AllPointsInterpolation: 1>, show_ap: bool = False, show_interpolated_precision: bool = False)\n",
            "        PlotPrecisionRecallCurve\n",
            "        Plot the Precision x Recall curve for a given class.\n",
            "        Args:\n",
            "            result: metric per class\n",
            "            dest: the plot will be saved as an image in this path\n",
            "            method: method for interpolation\n",
            "            show_ap: if True, the average precision value will be shown in the title of\n",
            "                the graph (default = False);\n",
            "            show_interpolated_precision (optional): if True, it will show in the plot the interpolated\n",
            "                precision (default = False);\n",
            "    \n",
            "    plot_precision_recall_curve_all(results: Dict[str, podm.podm.MetricPerClass], dest_dir, method: podm.podm.MethodAveragePrecision = <MethodAveragePrecision.AllPointsInterpolation: 1>, show_ap: bool = False, show_interpolated_precision: bool = False)\n",
            "        Plot the Precision x Recall curve for a given class.\n",
            "        \n",
            "        Args:\n",
            "            results: metric per class\n",
            "            dest_dir: the plot will be saved as an image in this path\n",
            "            method: method for interpolation\n",
            "            show_ap: if True, the average precision value will be shown in the title of\n",
            "                the graph (default = False);\n",
            "            show_interpolated_precision (optional): if True, it will show in the plot the interpolated\n",
            "                precision (default = False);\n",
            "\n",
            "DATA\n",
            "    Dict = typing.Dict\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.7/dist-packages/podm/visualize.py\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3pvG6RgoMtE",
        "outputId": "ea04b840-cc09-4073-ef63-170565e21cfd"
      },
      "source": [
        "from podm.podm import BoundingBox, get_pascal_voc_metrics\n",
        "\n",
        "image_name = \"test_img\"\n",
        "label = \"class_1\"\n",
        "w = 30.0\n",
        "h = 20.0\n",
        "xtl = 10.0\n",
        "ytl = 10.0\n",
        "xbr = xtl+w\n",
        "ybr = xtl+h\n",
        "score = 1.0\n",
        "\n",
        "bb_pd = BoundingBox(image_name, label, xtl-10.3, ytl-10.3, xbr, ybr, score)\n",
        "bb_gt = BoundingBox(image_name, label, xtl, ytl, xbr, ybr, score=None)\n",
        "alpha = .5\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGDfIPwjxhY6",
        "outputId": "f067244e-e06a-4f83-9184-4ac4d8636055"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG_d3T4jfuAb"
      },
      "source": [
        "### 4.2 Modelos entrenados\n",
        "\n",
        "Para cada modelo entrenado se detalla:\n",
        "\n",
        "- Descripción.\n",
        "- Arquitectura, parámetros.\n",
        "- Datos de entrada y sus transformaciones aplicadas.\n",
        "- Parámetros de entrenamiento.\n",
        "- Ambiente de entrenamiento.\n",
        "- Información adicional del entrenamiento: curvas, tiempo, \n",
        "- Resultado de evaluación final\n",
        "- Archivos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xov4sBjXgyKT"
      },
      "source": [
        " ### 4.2.1 YOLOv4 (Darknet)\n",
        "\n",
        " #### Arquitectura\n",
        "\n",
        " #### Datos de entrada\n",
        "\n",
        " #### Parámetros de entrenamiento\n",
        "\n",
        " #### Ambiente de entrenamiento\n",
        "\n",
        " #### Información del entrenamiento\n",
        "\n",
        " #### Evaluación\n",
        "\n",
        " #### Archivos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-Xkj-sGEEke"
      },
      "source": [
        "## Bibliografía y referencias"
      ]
    }
  ]
}